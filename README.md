# BERT-Based Spam Filtering Project

## Team Members
- Mateo Velarde
- Mohammad Fanous

## Abstract
In this project, we explore the application of the state-of-the-art natural language processing model, Bidirectional Encoder Representations from Transformers (BERT), for the purpose of spam detection. Our goal is to effectively classify text messages into spam or non-spam categories. Leveraging the powerful capabilities of BERT, which excels in understanding the context of a word in a sentence, we aim to develop a model that can accurately identify and filter out spam messages from various communication channels like emails and social media.

We utilize the SMS Spam Collection Dataset, which consists of labeled messages classified as either 'ham' (non-spam) or 'spam'. This project encompasses data preprocessing, where text data is cleaned and formatted, and model training, where a pre-trained BERT model is fine-tuned on our dataset. Our focus is on achieving high accuracy in spam detection, which is critical for enhancing the user experience by reducing the exposure to unwanted messages and potentially harmful content.

Data Source: https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset?resource=download
