{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cardiac MRI Superresolution by Mateo Velarde & Mohammad Fanous\n",
    "\n",
    "## Introduction\n",
    "In this notebook, we will implement a deep learning solution to improve the resolution of low-resolution cardiac MRI scans. \n",
    "The goal is to enhance the quality of the images, making diagnosis more accurate and reliable.\n",
    "\n",
    "## Importing Libraries\n",
    "Let's start by importing the necessary libraries for data processing, model building, and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, UpSampling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError, MeanAbsoluteError, BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import Mean, RootMeanSquaredError, MeanAbsoluteError\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mvelarde/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4457,) (1115,) (4457,) (1115,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the dataset\n",
    "def load_data(filename):\n",
    "    data = pd.read_csv(filename, encoding='latin-1')\n",
    "    data = data[['v1', 'v2']]\n",
    "    data.columns = ['label', 'message']\n",
    "    return data\n",
    "\n",
    "# Preprocess the data\n",
    "def preprocess_text(text):\n",
    "    # Remove email headers, PII, etc. (customize as needed)\n",
    "    text = re.sub(r'\\S*@\\S*\\s?', '', text)\n",
    "\n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'[^A-Za-z0-9 ]+', '', text)\n",
    "\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "\n",
    "    return text\n",
    "\n",
    "# Apply preprocessing\n",
    "def preprocess_data(data):\n",
    "    data['message'] = data['message'].apply(preprocess_text)\n",
    "    return data\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    filename = 'spam.csv' # Change this to the path of your dataset\n",
    "    data = load_data(filename)\n",
    "    processed_data = preprocess_data(data)\n",
    "\n",
    "    # Split data into input (X) and output (Y)\n",
    "    X = processed_data['message']\n",
    "    Y = processed_data['label']\n",
    "\n",
    "    # Optionally, split the data into training and testing sets\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "    # Output processed data\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "# Run the main function\n",
    "X_train, X_test, Y_train, Y_test = main()\n",
    "\n",
    "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
